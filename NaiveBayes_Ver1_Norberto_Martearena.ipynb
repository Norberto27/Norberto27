{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYZ/QoCzXNZ4dr9cp1ZKtI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Norberto27/Norberto27/blob/main/NaiveBayes_Ver1_Norberto_Martearena.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56oOQ3wvT-u4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Version 1**\n",
        "Al final del notebook, figuran los avances, Detalles y Experiencia de ambas versiones"
      ],
      "metadata": {
        "id": "JFjLQG6uHCxD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq6j8LsYq1Dr"
      },
      "source": [
        "### Vectorización de texto y modelo de clasificación Naïve Bayes con el dataset 20 newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7cXR6CI30ry"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
        "# en sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD-pVDWV_rQc"
      },
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ech9qJaUo9vK"
      },
      "outputs": [],
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxjSI7su_uWI"
      },
      "source": [
        "## Vectorización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-94VP0QYCzDn"
      },
      "outputs": [],
      "source": [
        "# instanciamos un vectorizador\n",
        "# ver diferentes parámetros de instanciación en la documentación de sklearn\n",
        "tfidfvect = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "ftPlyanuak8n",
        "outputId": "d7bad85a-ae40-4b3c-bc0c-8d63a64bc90a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# en el atributo `data` accedemos al texto\n",
        "newsgroups_train.data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zxcXV6aC_oL"
      },
      "outputs": [],
      "source": [
        "# con la interfaz habitual de sklearn podemos fitear el vectorizador\n",
        "# (obtener el vocabulario y calcular el vector IDF)\n",
        "# y transformar directamente los datos\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "# `X_train` la podemos denominar como la matriz documento-término"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sv7TXbda41-",
        "outputId": "33d34be1-5adc-442a-e476-c1a99b8b3191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "shape: (11314, 101631)\n",
            "cantidad de documentos: 11314\n",
            "tamaño del vocabulario (dimensionalidad de los vectores): 101631\n"
          ]
        }
      ],
      "source": [
        "# recordar que las vectorizaciones por conteos son esparsas\n",
        "# por ello sklearn convenientemente devuelve los vectores de documentos\n",
        "# como matrices esparsas\n",
        "print(type(X_train))\n",
        "print(f'shape: {X_train.shape}')\n",
        "print(f'cantidad de documentos: {X_train.shape[0]}')\n",
        "print(f'tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgydNTZ2pAgR",
        "outputId": "1604278d-5831-43e6-b1d8-9570528392f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25775"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# una vez ajustado el vectorizador, podemos acceder a atributos como el vocabulario\n",
        "# aprendido. Es un diccionario que va de términos a índices.\n",
        "# El índice es la posición en el vector de documento.\n",
        "tfidfvect.vocabulary_['car']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnTSZuvyrTcP"
      },
      "outputs": [],
      "source": [
        "# es muy útil tener el diccionario opuesto que va de índices a términos\n",
        "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swa-AgWrMSHM",
        "outputId": "0b44f666-7eb5-49cf-de0a-3be46ab6f7c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# en `y_train` guardamos los targets que son enteros\n",
        "y_train = newsgroups_train.target\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je5kxvQMDLvf",
        "outputId": "51b5bc19-ae5e-419d-ebfc-0037901ca217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clases [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# hay 20 clases correspondientes a los 20 grupos de noticias\n",
        "print(f'clases {np.unique(newsgroups_test.target)}')\n",
        "newsgroups_test.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Seleccionar 5 documentos al azar**"
      ],
      "metadata": {
        "id": "FqvlapysXD19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# Seleccionamos 5 documentos al azar del conjunto de entrenamiento\n",
        "import random\n",
        "\n",
        "# Fijar una semilla aleatoria\n",
        "random.seed(27)\n",
        "\n",
        "# Seleccionar 5 párrafos al azar\n",
        "random_docs = random.sample(newsgroups_train.data, 5)\n"
      ],
      "metadata": {
        "id": "AlEK-jCYXJDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Medir la similaridad de esos 5 documentos con el resto**"
      ],
      "metadata": {
        "id": "ptBAxyOPXUij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Calcular la similaridad de los documentos seleccionados con todos los documentos del conjunto\n",
        "for i, doc in enumerate(random_docs):\n",
        "    doc_vect = tfidfvect.transform([doc])  # Vectoriza el documento individual\n",
        "    cossim = cosine_similarity(doc_vect, X_train)[0]  # Similaridad con todos los documentos de train\n",
        "    mostsim = np.argsort(cossim)[::-1][1:6]  # 5 documentos más similares, excluyendo el mismo documento\n",
        "\n",
        "    # Muestra la clase del documento seleccionado\n",
        "    print(f'Documento {i} pertenece a la clase: {newsgroups_train.target_names[y_train[newsgroups_train.data.index(doc)]]}')\n",
        "\n",
        "    # Muestra los 5 documentos más similares\n",
        "    print(f'Los 5 documentos más similares son:')\n",
        "    for idx in mostsim:\n",
        "        print(f'Clase: {newsgroups_train.target_names[y_train[idx]]}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_s9ebdOXcoS",
        "outputId": "9275bf58-46c3-48fa-d189-5f84aa0ea7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento 0 pertenece a la clase: soc.religion.christian\n",
            "Los 5 documentos más similares son:\n",
            "Clase: alt.atheism\n",
            "Clase: talk.religion.misc\n",
            "Clase: soc.religion.christian\n",
            "Clase: soc.religion.christian\n",
            "Clase: soc.religion.christian\n",
            "Documento 1 pertenece a la clase: rec.autos\n",
            "Los 5 documentos más similares son:\n",
            "Clase: sci.electronics\n",
            "Clase: sci.electronics\n",
            "Clase: comp.os.ms-windows.misc\n",
            "Clase: soc.religion.christian\n",
            "Clase: rec.autos\n",
            "Documento 2 pertenece a la clase: rec.sport.hockey\n",
            "Los 5 documentos más similares son:\n",
            "Clase: rec.sport.hockey\n",
            "Clase: rec.sport.baseball\n",
            "Clase: rec.sport.hockey\n",
            "Clase: rec.sport.hockey\n",
            "Clase: rec.sport.hockey\n",
            "Documento 3 pertenece a la clase: rec.motorcycles\n",
            "Los 5 documentos más similares son:\n",
            "Clase: rec.motorcycles\n",
            "Clase: misc.forsale\n",
            "Clase: misc.forsale\n",
            "Clase: misc.forsale\n",
            "Clase: misc.forsale\n",
            "Documento 4 pertenece a la clase: comp.os.ms-windows.misc\n",
            "Los 5 documentos más similares son:\n",
            "Clase: comp.graphics\n",
            "Clase: sci.crypt\n",
            "Clase: comp.os.ms-windows.misc\n",
            "Clase: comp.os.ms-windows.misc\n",
            "Clase: comp.graphics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Entrenar modelos Naïve Bayes**"
      ],
      "metadata": {
        "id": "QsNbXTb0amX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Entrenamos el modelo Naive Bayes Multinomial\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Vectorizamos los datos de prueba y predecimos\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculamos el F1-score con promediado macro\n",
        "print(f'F1-score (macro): {f1_score(newsgroups_test.target, y_pred, average=\"macro\")}')\n"
      ],
      "metadata": {
        "id": "eem02_1Ybk46",
        "outputId": "c778884a-6ae0-4083-a4ad-2da14c0a4707",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score (macro): 0.5854345727938506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transponer la matriz y estudiar la similaridad entre palabras**"
      ],
      "metadata": {
        "id": "mNLBrRiLzlXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transponemos la matriz documento-término\n",
        "X_train_transposed = X_train.T\n",
        "\n",
        "# Elegimos manualmente 5 palabras para estudiar su similaridad\n",
        "palabras = ['car', 'computer', 'government', 'money', 'health']\n",
        "\n",
        "for palabra in palabras:\n",
        "    idx = tfidfvect.vocabulary_[palabra]\n",
        "    palabra_vect = X_train_transposed[idx]  # Vectoriza la palabra individualmente\n",
        "    similar_words = cosine_similarity(palabra_vect, X_train_transposed)[0]  # Similaridad con otras palabras\n",
        "    most_similar_idx = np.argsort(similar_words)[::-1][1:6]  # Las 5 palabras más similares\n",
        "    print(f'Palabra: {palabra}')\n",
        "    for idx in most_similar_idx:\n",
        "        print(f'Palabra similar: {idx2word[idx]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fusCx_8Tzt2R",
        "outputId": "30bef217-83d3-47a1-eabc-2c80532345a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabra: car\n",
            "Palabra similar: cars\n",
            "Palabra similar: criterium\n",
            "Palabra similar: civic\n",
            "Palabra similar: owner\n",
            "Palabra similar: dealer\n",
            "Palabra: computer\n",
            "Palabra similar: decwriter\n",
            "Palabra similar: harkens\n",
            "Palabra similar: deluged\n",
            "Palabra similar: shopper\n",
            "Palabra similar: the\n",
            "Palabra: government\n",
            "Palabra similar: the\n",
            "Palabra similar: to\n",
            "Palabra similar: of\n",
            "Palabra similar: libertarian\n",
            "Palabra similar: encryption\n",
            "Palabra: money\n",
            "Palabra similar: buyback\n",
            "Palabra similar: computerize\n",
            "Palabra similar: fundraising\n",
            "Palabra similar: to\n",
            "Palabra similar: spend\n",
            "Palabra: health\n",
            "Palabra similar: ohip\n",
            "Palabra similar: provincial\n",
            "Palabra similar: care\n",
            "Palabra similar: traditionalists\n",
            "Palabra similar: fiscally\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Informe de Resultados: Comparación de Modelos Naive Bayes**\n",
        "1. Introducción\n",
        "El objetivo de este análisis fue entrenar y evaluar modelos de clasificación utilizando Naive Bayes, con el fin de maximizar el F1-score (macro) en un conjunto de datos de texto (datasets grupos de noticias). Para esto, se exploraron dos enfoques diferentes de vectorización: uno básico (Versión 1) y otro con ajustes de hiperparámetros (Versión 2). A través de esta comparación, se buscó entender cómo la modificación en los parámetros del TfidfVectorizer afecta el rendimiento del modelo.\n",
        "2. Descripción de las versiones\n",
        "Durante el análisis, se probaron dos enfoques distintos para la vectorización de los datos:\n",
        "Enfoque 1: Vectorización básica (Versión 1)\n",
        "En la primera versión, se utilizó el método básico de vectorización de texto utilizando TfidfVectorizer con sus valores predeterminados. Este enfoque permite transformar los textos en vectores sin realizar ningún tipo de ajuste o filtro adicional.\n",
        "•\tTfidfVectorizer(): Usado con los parámetros por defecto.\n",
        "Enfoque 2: Ajuste de hiperparámetros (Versión 2)\n",
        "En la segunda versión, se realizaron ajustes en los hiperparámetros del TfidfVectorizer para mejorar la representación de los textos y ver si esto impactaba en el rendimiento del modelo.\n",
        "•\tTfidfVectorizer(max_df=0.8, min_df=2, ngram_range=(1, 2), sublinear_tf=True):\n",
        "o\tmax_df=0.8: Excluye términos muy frecuentes que aparecen en más del 80% de los documentos.\n",
        "o\tmin_df=2: Excluye términos que aparecen en menos de 2 documentos.\n",
        "o\tngram_range=(1, 2): Considera tanto unigramas como bigramas.\n",
        "o\tsublinear_tf=True: Aplica una transformación sublineal a las frecuencias de término.\n",
        "3. Resultados\n",
        "Se midió el F1-score (macro) para ambas versiones con el fin de evaluar el rendimiento de cada enfoque. A continuación, se presenta una comparación de los resultados obtenidos:\n",
        "F1-score de la versión 1 (Vectorización básica):\n",
        "•\tF1-score (macro): 0.5854345727938506\n",
        "F1-score de la versión 2 (Ajuste de hiperparámetros):\n",
        "•\tF1-score (macro): 0.5745979561373709\n",
        "Comparación de resultados:\n",
        "El rendimiento del modelo mostró diferencias entre ambos enfoques. En la versión básica, se obtuvo un F1-score inicial que sirvió como línea base. Tras ajustar los hiperparámetros, se observó 0.5746, ligeramente más bajo que el original de 0.5854.\n",
        "Posibles razones del comportamiento observado:\n",
        "•\tEnfoque 1 (básico): Al no realizar ningún ajuste en los parámetros, el modelo se entrenó con una representación más general de los textos, lo que puede haber permitido capturar términos relevantes, pero también introducir ruido.\n",
        "•\tEnfoque 2 (ajuste de hiperparámetros): Los ajustes en la vectorización permitieron filtrar términos muy frecuentes y poco representativos, además de considerar combinaciones de palabras (bigramas), lo que podría haber mejorado la calidad de la representación de los textos. Sin embargo, en este caso, el ajuste no logró mejorar el F1-score. Esto puede deberse a que los bigramas no aportaron información adicional suficiente o a que el modelo Naive Bayes no se beneficia tanto de este tipo de ajustes en algunos conjuntos de datos.\n",
        "4. Conclusión final\n",
        "El proceso de ajuste de hiperparámetros es una etapa fundamental en el desarrollo de modelos de aprendizaje automático. En este análisis, a pesar de los ajustes realizados en la vectorización de los textos, el rendimiento en términos de F1-score (macro) no mejoró en comparación con el enfoque básico.\n",
        "Sin embargo, el aprendizaje obtenido durante este proceso fue valioso, ya que me permitió entender mejor cómo afectan las diferentes configuraciones de los parámetros a la representación de los datos y al rendimiento del modelo. Además, comprobe que los ajustes de hiperparámetros no siempre garantizan una mejora en el rendimiento, pero forman parte esencial del ciclo iterativo de optimización de modelos.\n",
        "Este análisis será una base para futuras mejoras, donde podrían probarse otros algoritmos o enfoques para mejorar el rendimiento del modelo de clasificación.\n"
      ],
      "metadata": {
        "id": "9HIhZsd9r71B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reflexion Final (Experiencia)**\n",
        "\n",
        "Problemas Enfrentados y Experiencia Adicional\n",
        "Durante el desarrollo de este proyecto, me surgieron varios desafíos que enriquecieron mi experiencia y permitieron un aprendizaje más profundo sobre la implementación de modelos de clasificación basados en Naive Bayes. Estos problemas abarcaron tanto la preparación de los datos como la optimización de los modelos. A continuación, hago un breve  resumen de los principales problemas y lecciones aprendidas:\n",
        "1.\tVectorización de Datos Textuales:\n",
        "o\tProblema: La representación de los textos fue uno de los principales retos. Al trabajar con datos textuales, elegir una adecuada vectorización era crucial para obtener buenos resultados. En la primera versión, se utilizó un enfoque básico de TfidfVectorizer, que arrojó resultados decentes, pero no óptimos.\n",
        "o\tLección: La elección de los parámetros de la vectorización tiene un impacto significativo en la calidad de los datos utilizados por el modelo. Sin embargo, pequeños cambios en los hiperparámetros no siempre producen mejoras considerables, lo que lleva a la importancia de experimentar y probar múltiples configuraciones.\n",
        "2.\tAjustes de Hiperparámetros:\n",
        "o\tProblema: Al ajustar los hiperparámetros de la vectorización, se esperaba mejorar el rendimiento del modelo. No obstante, en algunos casos los cambios no produjeron una mejora en el F1-score, lo que podría atribuirse a la naturaleza del conjunto de datos y la idoneidad del modelo Naive Bayes para este tipo de tareas.\n",
        "o\tLección: El ajuste de hiperparámetros no es una solución garantizada para mejorar el rendimiento, y a veces los cambios pueden no ser suficientes o incluso degradar el rendimiento. Esto refuerza la importancia de probar diversas combinaciones de hiperparámetros, así como la necesidad de profundizar en el entendimiento de cómo el modelo interactúa con los datos.\n",
        "3.\tAleatoriedad y Semillas de Datos:\n",
        "o\tProblema: La segunda ejecución (con ajuste en hiperparametros) los resultados fueron distintos porque por error se tomaron 5 documentos al azar diferentes. Por ello, se fijo una semilla aleatoria.\n",
        "o\tLección: Fijar semillas aleatorias es fundamental cuando se trabaja con selección de muestras aleatorias. Sin embargo, es importante también entender que ciertos algoritmos o funciones pueden depender de múltiples factores, y la variabilidad en los resultados puede reflejar la naturaleza del conjunto de datos o el impacto del procesamiento de características.\n",
        "4.\tSimilaridad entre Documentos:\n",
        "o\tProblema: Al medir la similaridad de los documentos seleccionados, algunos resultados mostraron cierta dispersión entre clases, lo que evidenció la complejidad del conjunto de datos. En varios casos, documentos de clases distintas aparecieron como los más similares, lo que llevó a una revisión del modelo de vectorización.\n",
        "o\tLección: La similaridad entre documentos no siempre es intuitiva, y un análisis más detallado de los datos podría ser necesario para entender las relaciones que el modelo detecta. Esto invita a explorar otros enfoques como redes neuronales o técnicas más avanzadas de procesamiento de lenguaje natural (NLP).\n",
        "Reflexión Final\n",
        "Cada uno de estos desafíos presentó una oportunidad de aprendizaje que permitió mejorar la comprensión tanto de los algoritmos como de los datos con los que se trabajaba. La experiencia adquirida al resolver estos problemas será valiosa en futuros proyectos, tanto para ajustar la vectorización de textos como para aplicar modelos más adecuados y técnicas de ajuste de hiperparámetros más avanzadas.\n"
      ],
      "metadata": {
        "id": "3IIf6CiFsrI8"
      }
    }
  ]
}