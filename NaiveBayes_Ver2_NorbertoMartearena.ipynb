{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKlIq0RTmPlerw2bWsMLMz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Norberto27/Norberto27/blob/main/NaiveBayes_Ver2_NorbertoMartearena.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56oOQ3wvT-u4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **VERSION 2**\n",
        "\n",
        "CON AJUSTE DE HIPERPARAMETROS"
      ],
      "metadata": {
        "id": "fGJCOAU7H4lr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq6j8LsYq1Dr"
      },
      "source": [
        "### Vectorización de texto y modelo de clasificación Naïve Bayes con el dataset 20 newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7cXR6CI30ry"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
        "# en sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD-pVDWV_rQc"
      },
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ech9qJaUo9vK"
      },
      "outputs": [],
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxjSI7su_uWI"
      },
      "source": [
        "## Vectorización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-94VP0QYCzDn"
      },
      "outputs": [],
      "source": [
        "# instanciamos un vectorizador\n",
        "# ver diferentes parámetros de instanciación en la documentación de sklearn\n",
        "# tfidfvect = TfidfVectorizer()\n",
        "tfidfvect = TfidfVectorizer(max_df=0.8, min_df=2, ngram_range=(1, 2), sublinear_tf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "ftPlyanuak8n",
        "outputId": "6adc5a22-b6cb-4773-ed5f-d4fff56d8ba2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# en el atributo `data` accedemos al texto\n",
        "newsgroups_train.data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zxcXV6aC_oL"
      },
      "outputs": [],
      "source": [
        "# con la interfaz habitual de sklearn podemos fitear el vectorizador\n",
        "# (obtener el vocabulario y calcular el vector IDF)\n",
        "# y transformar directamente los datos\n",
        "# X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "# `X_train` la podemos denominar como la matriz documento-término\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sv7TXbda41-",
        "outputId": "af9ed2e7-a4cf-4bf6-ff82-1fe7f4779a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "shape: (11314, 230758)\n",
            "cantidad de documentos: 11314\n",
            "tamaño del vocabulario (dimensionalidad de los vectores): 230758\n"
          ]
        }
      ],
      "source": [
        "# recordar que las vectorizaciones por conteos son esparsas\n",
        "# por ello sklearn convenientemente devuelve los vectores de documentos\n",
        "# como matrices esparsas\n",
        "print(type(X_train))\n",
        "print(f'shape: {X_train.shape}')\n",
        "print(f'cantidad de documentos: {X_train.shape[0]}')\n",
        "print(f'tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgydNTZ2pAgR",
        "outputId": "99649538-58f1-4306-df26-ffb66d2d3890"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44991"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# una vez ajustado el vectorizador, podemos acceder a atributos como el vocabulario\n",
        "# aprendido. Es un diccionario que va de términos a índices.\n",
        "# El índice es la posición en el vector de documento.\n",
        "tfidfvect.vocabulary_['car']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnTSZuvyrTcP"
      },
      "outputs": [],
      "source": [
        "# es muy útil tener el diccionario opuesto que va de índices a términos\n",
        "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swa-AgWrMSHM",
        "outputId": "8a7c6bb5-d6ed-4301-bb85-826578af37b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# en `y_train` guardamos los targets que son enteros\n",
        "y_train = newsgroups_train.target\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je5kxvQMDLvf",
        "outputId": "4542ef33-2030-418a-9080-5ed0e876373c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clases [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# hay 20 clases correspondientes a los 20 grupos de noticias\n",
        "print(f'clases {np.unique(newsgroups_test.target)}')\n",
        "newsgroups_test.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Seleccionar 5 documentos al azar**"
      ],
      "metadata": {
        "id": "FqvlapysXD19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# Seleccionamos 5 documentos al azar del conjunto de entrenamiento\n",
        "import random\n",
        "\n",
        "# Fijar una semilla aleatoria\n",
        "random.seed(27)\n",
        "\n",
        "# Seleccionar 5 párrafos al azar\n",
        "random_docs = random.sample(newsgroups_train.data, 5)\n",
        "\n"
      ],
      "metadata": {
        "id": "AlEK-jCYXJDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Medir la similaridad de esos 5 documentos con el resto**"
      ],
      "metadata": {
        "id": "ptBAxyOPXUij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Calcular la similaridad de los documentos seleccionados con todos los documentos del conjunto\n",
        "for i, doc in enumerate(random_docs):\n",
        "    doc_vect = tfidfvect.transform([doc])  # Vectoriza el documento individual\n",
        "    cossim = cosine_similarity(doc_vect, X_train)[0]  # Similaridad con todos los documentos de train\n",
        "    mostsim = np.argsort(cossim)[::-1][1:6]  # 5 documentos más similares, excluyendo el mismo documento\n",
        "\n",
        "    # Muestra la clase del documento seleccionado\n",
        "    print(f'Documento {i} pertenece a la clase: {newsgroups_train.target_names[y_train[newsgroups_train.data.index(doc)]]}')\n",
        "\n",
        "    # Muestra los 5 documentos más similares\n",
        "    print(f'Los 5 documentos más similares son:')\n",
        "    for idx in mostsim:\n",
        "        print(f'Clase: {newsgroups_train.target_names[y_train[idx]]}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_s9ebdOXcoS",
        "outputId": "07207d99-b991-4631-dd7d-61988cf851c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento 0 pertenece a la clase: soc.religion.christian\n",
            "Los 5 documentos más similares son:\n",
            "Clase: rec.motorcycles\n",
            "Clase: soc.religion.christian\n",
            "Clase: talk.politics.misc\n",
            "Clase: soc.religion.christian\n",
            "Clase: alt.atheism\n",
            "Documento 1 pertenece a la clase: rec.autos\n",
            "Los 5 documentos más similares son:\n",
            "Clase: comp.windows.x\n",
            "Clase: comp.sys.ibm.pc.hardware\n",
            "Clase: rec.motorcycles\n",
            "Clase: comp.graphics\n",
            "Clase: soc.religion.christian\n",
            "Documento 2 pertenece a la clase: rec.sport.hockey\n",
            "Los 5 documentos más similares son:\n",
            "Clase: rec.sport.hockey\n",
            "Clase: rec.sport.baseball\n",
            "Clase: rec.sport.hockey\n",
            "Clase: rec.sport.hockey\n",
            "Clase: rec.sport.hockey\n",
            "Documento 3 pertenece a la clase: rec.motorcycles\n",
            "Los 5 documentos más similares son:\n",
            "Clase: rec.motorcycles\n",
            "Clase: misc.forsale\n",
            "Clase: misc.forsale\n",
            "Clase: misc.forsale\n",
            "Clase: misc.forsale\n",
            "Documento 4 pertenece a la clase: comp.os.ms-windows.misc\n",
            "Los 5 documentos más similares son:\n",
            "Clase: sci.med\n",
            "Clase: comp.graphics\n",
            "Clase: comp.os.ms-windows.misc\n",
            "Clase: comp.sys.ibm.pc.hardware\n",
            "Clase: comp.os.ms-windows.misc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Entrenar modelos Naïve Bayes**"
      ],
      "metadata": {
        "id": "QsNbXTb0amX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Entrenamos el modelo Naive Bayes Multinomial\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Vectorizamos los datos de prueba y predecimos\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculamos el F1-score con promediado macro\n",
        "print(f'F1-score (macro): {f1_score(newsgroups_test.target, y_pred, average=\"macro\")}')\n"
      ],
      "metadata": {
        "id": "eem02_1Ybk46",
        "outputId": "2ee61da5-b58b-42b4-b295-a75ad65a965c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score (macro): 0.5745979561373709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transponer la matriz y estudiar la similaridad entre palabras**"
      ],
      "metadata": {
        "id": "mNLBrRiLzlXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transponemos la matriz documento-término\n",
        "X_train_transposed = X_train.T\n",
        "\n",
        "# Elegimos manualmente 5 palabras para estudiar su similaridad\n",
        "palabras = ['car', 'computer', 'government', 'money', 'health']\n",
        "\n",
        "for palabra in palabras:\n",
        "    idx = tfidfvect.vocabulary_[palabra]\n",
        "    palabra_vect = X_train_transposed[idx]  # Vectoriza la palabra individualmente\n",
        "    similar_words = cosine_similarity(palabra_vect, X_train_transposed)[0]  # Similaridad con otras palabras\n",
        "    most_similar_idx = np.argsort(similar_words)[::-1][1:6]  # Las 5 palabras más similares\n",
        "    print(f'Palabra: {palabra}')\n",
        "    for idx in most_similar_idx:\n",
        "        print(f'Palabra similar: {idx2word[idx]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fusCx_8Tzt2R",
        "outputId": "f7bc9c55-f29d-42dc-f189-b5ef5a65a44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabra: car\n",
            "Palabra similar: the car\n",
            "Palabra similar: car and\n",
            "Palabra similar: car is\n",
            "Palabra similar: car in\n",
            "Palabra similar: my car\n",
            "Palabra: computer\n",
            "Palabra similar: the computer\n",
            "Palabra similar: my computer\n",
            "Palabra similar: computer science\n",
            "Palabra similar: your computer\n",
            "Palabra similar: computer graphics\n",
            "Palabra: government\n",
            "Palabra similar: the government\n",
            "Palabra similar: government is\n",
            "Palabra similar: of government\n",
            "Palabra similar: government has\n",
            "Palabra similar: government to\n",
            "Palabra: money\n",
            "Palabra similar: the money\n",
            "Palabra similar: money for\n",
            "Palabra similar: of money\n",
            "Palabra similar: money to\n",
            "Palabra similar: money and\n",
            "Palabra: health\n",
            "Palabra similar: health care\n",
            "Palabra similar: health insurance\n",
            "Palabra similar: of health\n",
            "Palabra similar: public health\n",
            "Palabra similar: the health\n"
          ]
        }
      ]
    }
  ]
}